{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BSplineActivation(nn.Module):\n",
    "    def __init__(self, num_points=5, domain=(-1, 1)):\n",
    "        super(BSplineActivation, self).__init__()\n",
    "        # Number of B-spline grid points (trainable parameters)\n",
    "        self.num_points = num_points\n",
    "        self.domain = domain\n",
    "        \n",
    "        # Trainable grid points (control points for the B-spline)\n",
    "        self.grid_points = nn.Parameter(torch.linspace(domain[0], domain[1], num_points))\n",
    "        \n",
    "        # Coefficients for each B-spline segment\n",
    "        self.coefficients = nn.Parameter(torch.ones(num_points))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Map input x to be in the domain of [-1, 1]\n",
    "        x = torch.clamp(x, self.domain[0], self.domain[1])\n",
    "        \n",
    "        # Find the indices of the grid points\n",
    "        grid_indices = torch.bucketize(x, self.grid_points)\n",
    "\n",
    "        # Interpolate between the grid points using B-splines\n",
    "        output = torch.zeros_like(x)\n",
    "        for i in range(self.num_points - 1):\n",
    "            mask = (grid_indices == i)\n",
    "            output[mask] = self.coefficients[i] * (x[mask] - self.grid_points[i])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KANModel(nn.Module):\n",
    "    def __init__(self, input_size=28*28, hidden_size=512, output_size=10, num_splines=5):\n",
    "        super(KANModel, self).__init__()\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # B-spline activations\n",
    "        self.b_spline = BSplineActivation(num_points=num_splines)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten the input image\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Apply layers with B-spline activations\n",
    "        x = self.fc1(x)\n",
    "        x = self.b_spline(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.b_spline(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KAN model...\n",
      "Epoch 1, Loss: 0.40556850476559797\n",
      "Epoch 2, Loss: 0.22589783714428893\n",
      "Epoch 3, Loss: 0.2111099288721424\n",
      "Epoch 4, Loss: 0.21233184316725745\n",
      "Epoch 5, Loss: 0.22737231423288012\n",
      "Evaluating KAN model...\n",
      "Accuracy: 93.02%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Define the transform for the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset from Hugging Face\n",
    "dataset = load_dataset(\"ylecun/mnist\")\n",
    "\n",
    "# Define a custom Dataset class for MNIST with transformation\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[idx]['image']\n",
    "        label = self.dataset[idx]['label']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Apply the transformation to the dataset\n",
    "train_dataset = MNISTDataset(dataset['train'], transform)\n",
    "test_dataset = MNISTDataset(dataset['test'], transform)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Instantiate the models\n",
    "kan_model = KANModel(input_size=28*28, hidden_size=512, output_size=10, num_splines=5)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "kan_optimizer = optim.Adam(kan_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop for MLP and KAN\n",
    "def train(model, train_loader, optimizer, criterion, num_epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"Training KAN model...\")\n",
    "train(kan_model, train_loader, kan_optimizer, criterion)\n",
    "\n",
    "# Testing function to evaluate model\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "print(\"Evaluating KAN model...\")\n",
    "test(kan_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.5185\n",
      "Epoch 2/10, Loss: 0.2424\n",
      "Epoch 3/10, Loss: 0.1857\n",
      "Epoch 4/10, Loss: 0.1526\n",
      "Epoch 5/10, Loss: 0.1316\n",
      "Epoch 6/10, Loss: 0.1133\n",
      "Epoch 7/10, Loss: 0.1018\n",
      "Epoch 8/10, Loss: 0.0882\n",
      "Epoch 9/10, Loss: 0.0856\n",
      "Epoch 10/10, Loss: 0.0749\n",
      "Accuracy: 97.03%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class KANModelWithGridExtension(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_splines=10):\n",
    "        super(KANModelWithGridExtension, self).__init__()\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Define trainable grid points for the B-splines\n",
    "        self.grid_points = nn.Parameter(torch.randn(num_splines))\n",
    "        \n",
    "        # Set number of splines\n",
    "        self.num_splines = num_splines\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # First hidden layer\n",
    "        x = self.fc1(x.view(x.size(0), -1))  # Flatten the input\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # Apply the KAN activation with grid extension\n",
    "        x = self.kan_activation(x)\n",
    "        \n",
    "        # Second layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def kan_activation(self, x):\n",
    "        # Apply a simple form of grid-based activation\n",
    "        # Interpolate activations based on grid points\n",
    "        grid_values = self.interpolate_grid(x, self.grid_points)\n",
    "        return grid_values\n",
    "    \n",
    "    def interpolate_grid(self, x, grid_points):\n",
    "        # Linear interpolation function between grid points and activations\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Normalize x to [0, 1]\n",
    "        min_val, _ = torch.min(x, dim=1, keepdim=True)\n",
    "        max_val, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        norm_x = (x - min_val) / (max_val - min_val + 1e-6)  # Avoid division by zero\n",
    "        \n",
    "        # Rescale norm_x to map it to the range of the grid points\n",
    "        grid_size = grid_points.size(0) - 1\n",
    "        indices = torch.floor(norm_x * grid_size).long()  # Get the indices for interpolation\n",
    "        \n",
    "        # Get the fractional part of norm_x\n",
    "        frac = norm_x * grid_size - indices.float()\n",
    "        \n",
    "        # Ensure indices are within valid range\n",
    "        indices = torch.clamp(indices, 0, grid_size - 1)\n",
    "        \n",
    "        # Interpolate between the grid points\n",
    "        lower = grid_points[indices]\n",
    "        upper = grid_points[indices + 1]\n",
    "        \n",
    "        # Linear interpolation formula\n",
    "        interp_values = lower + frac * (upper - lower)\n",
    "        \n",
    "        return interp_values\n",
    "\n",
    "# Check if a GPU is available, otherwise use the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model with grid extension and send it to the selected device\n",
    "kan_model_with_grid = KANModelWithGridExtension(input_dim=28*28, hidden_dim=128, output_dim=10, num_splines=20).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(kan_model_with_grid.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with grid extension\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    kan_model_with_grid.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        outputs = kan_model_with_grid(images)  # Forward pass\n",
    "        loss = loss_fn(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "kan_model_with_grid.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = kan_model_with_grid(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAN model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save KAN model\n",
    "torch.save(kan_model_with_grid.state_dict(), \"kan_model.pt\")\n",
    "print(\"KAN model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
